
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import sklearn.metrics as sk_met
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
import pickle
import tkinter as tk
from tkinter import filedialog
import cv2 as cv

def cnn_model(x_train,y_train,x_test,y_test):
    img = tf.keras.Input(shape=(224,224,1))

    Z1 = tf.keras.layers.Conv2D(filters=40, kernel_size=5, strides=1, padding='same')(img)
    
    A1 = tf.keras.layers.ReLU()(Z1)
    
    P1 = tf.keras.layers.MaxPool2D(pool_size=2, strides=1, padding='same')(A1)
    
    Z2 = tf.keras.layers.Conv2D(filters=20, kernel_size=3, strides=1, padding='same')(P1)

    A2 = tf.keras.layers.ReLU()(Z2)

    P2 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid')(A2)
    
    Drop1=tf.keras.layers.Dropout(0.3)(P2)

    F = tf.keras.layers.Flatten()(Drop1)
    
    D1=tf.keras.layers.Dense(activation='relu',units=130)(F)
    
    Drop2=tf.keras.layers.Dropout(0.4)(D1)
    
    D2=tf.keras.layers.Dense(units=50,activation='relu')(Drop2)
    
    output = tf.keras.layers.Dense(units=26, activation='softmax')(D2)
    
    model=tf.keras.Model(inputs=img,outputs=output)
    
    model.summary()
    
    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
    
    model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=5)
    
    model.save("cnn_model.keras")
    
    y_pred=model.predict(x_test)
    y_pred=np.argmax(y_pred,axis=1)
    y_testlab=np.argmax(y_test,axis=1)
    
    con_mat=sk_met.confusion_matrix(y_testlab, y_pred)
    sns.heatmap(data=con_mat,annot=True,fmt='.1f')
    plt.ylabel('Predicted')
    plt.xlabel('actual val')
    plt.title('Confusion matrix CNN')
    plt.show()

def softmax(z):
    s=np.exp(z)/np.sum(np.exp(z),axis=0,keepdims=True)
    return s

def initialization(n_x,c):
    w = np.random.randn(n_x,c)*0.01
    b = np.zeros((c,1))
    return w,b


def propagate(w, b, x, y):
    
    Z=np.dot(w.T,x)+b

    A=softmax(Z)
    
    return A

def gradient_descent(w,b,x,y,n_i,lr):
    yplt=[]
    yplt=np.array(yplt)
    
    xplt=[]
    xplt=np.array(xplt)
    
    m=x.shape[1]
    
    print(x.shape)
    
    print(y.shape)
    
    for i in range(n_i):
        xplt=np.append(xplt,i)
        
        A=propagate(w,b,x,y)
      

        dw = 1/m*(np.dot(x,(A-y).T))
      
        db = (np.sum(A-y))/m
        
        cost = (1/m) *(np.sum(-y*np.log(A)))
        
        yplt=np.append(yplt,cost)
        
        if i%100==0:
            print("cost at %i th iteration is %f" %(i,cost))
        
        w = w - (lr*dw)
        b = b - (lr*db)
        
    plt.plot(xplt, yplt)
    plt.xlabel('no. of iterations')
    plt.ylabel('Cost')
    plt.title('cost function(logistic regression)')
    plt.show()
        
    return w,b

def prediction(w,b,x,y):
    m = x.shape[1]
    
    A = softmax(w.T.dot(x) + b)
    
    A=np.argmax(A,axis=0)
    y=np.argmax(y,axis=0)
    ans=0
    
    for i in range(m):
        if A[i]==y[i]:
            ans+=1
    
    return ans/m

def model(x_train, y_train, x_test, y_test, n_i, lr):
   
    w,b=initialization(x_train.shape[0],y_train.shape[0])
    
    w,b=gradient_descent(w, b, x_train, y_train, n_i, lr)
    
    np.save('logistic_regression_weights', w)
    np.save('logistic_regression_constants',b)
    
    Y_prediction_test = prediction(w, b, x_test,y_test)
    Y_prediction_train = prediction(w, b, x_train,y_train)
    
    print("train accuracy: {} %".format(Y_prediction_train*100))
    print("test accuracy: {} %".format(Y_prediction_test*100))
    

def randomforestmodel(x_train,y_train,x_test,y_test):
    model=RandomForestClassifier(n_estimators=200)
    model.fit(x_train,y_train)
    
    y_pred=model.predict(x_train)
    
    m=y_train.shape[0]
    
    y_pred=np.argmax(y_pred,axis=1)
    y_train_lab=np.argmax(y_train,axis=1)
    ans=0
    
    for i in range(m):
        if y_pred[i]==y_train_lab[i]:
            ans+=1
    
    print("training accuracy of random forest= {} %".format((ans/m)*100))
    
    y_pred=model.predict(x_test)
    
    m=y_test.shape[0]
    
    y_pred=np.argmax(y_pred,axis=1)
    y_test_lab=np.argmax(y_test,axis=1)
    ans=0
    
    for i in range(m):
        if y_pred[i]==y_test_lab[i]:
            ans+=1
    
    print("testing accuracy of random forest= {} %".format((ans/m)*100))
    
    con_mat=sk_met.confusion_matrix(y_test_lab, y_pred)
    sns.heatmap(data=con_mat,annot=True,fmt='.1f')
    plt.ylabel('Predicted')
    plt.xlabel('actual val')
    plt.title('Confusion matrix random forest')
    plt.show()
    
    pickle.dump(model, open('randomforest.sav','wb')) 
    

ch=input("press 0 to train models or 1 to load the pre-trained models to test it on a file or 2 to load a copy of the training process\n")

if ch=="0":
    path_root = "malevis_train_val_224x224\\malevis_train_val_224x224\\train\\"
    batches = ImageDataGenerator().flow_from_directory(directory=path_root,target_size=(224,224),color_mode="grayscale",batch_size=9100)
    imgs, labels = next(batches)
    imgs=imgs/255

    path_root_val = "malevis_train_val_224x224\\malevis_train_val_224x224\\val\\"
    batches_val = ImageDataGenerator().flow_from_directory(directory=path_root_val,target_size=(224,224),color_mode="grayscale",batch_size=5126)
    imgs_val, labels_val = next(batches_val)
    
    print("printing the malware classes")

    print(batches_val.class_indices)
    
    pickle.dump(batches_val.class_indices,open('keys.sav','wb'))

    imgs_val=imgs_val/255
    
    print("training CNN model\n")
    cnn_model(imgs,labels,imgs_val,labels_val)
    
    print("training logistic regression model\n")
    model((np.reshape(imgs,(imgs.shape[0],-1))).T, labels.T, (np.reshape(imgs_val,(imgs_val.shape[0],-1))).T,labels_val.T, n_i = 2000, lr = 0.005)
    
    
    print("training random forest model\n")
    randomforestmodel(np.reshape(imgs,(imgs.shape[0],-1)), labels, np.reshape(imgs_val,(imgs_val.shape[0],-1)),labels_val)
    
elif ch=="1":
    w_mal=np.load('logistic_regression_weights.npy')
    
    b_mal=np.load('logistic_regression_constants.npy')
    
    cnn_model_mal=tf.keras.models.load_model("cnn_model.keras")
    
    random_forest_mal=pickle.load(open('randomforest.sav','rb'))
    
    keys=pickle.load(open('keys.sav','rb'))
    
    print("please select your file from the opened dialog box")
    
    root = tk.Tk()
    root.withdraw()

    file_path = filedialog.askopenfilename()
    
    mal_img=cv.imread(file_path,cv.IMREAD_GRAYSCALE)
    
    mal_img=np.reshape(mal_img,(1,mal_img.shape[0],-1))
    
    mal_img=mal_img/255
    
    cnn_pred=cnn_model_mal.predict(mal_img)
    cnn_pred=np.argmax(cnn_pred,axis=1)
    cnn_pred=[k for k,v in keys.items() if v==cnn_pred]
    
    rf_pred=random_forest_mal.predict(np.reshape(mal_img,(mal_img.shape[0],-1)))
    rf_pred=np.argmax(rf_pred,axis=1)
    rf_pred=[k for k,v in keys.items() if v==rf_pred]
    
    log_pred=softmax(w_mal.T.dot((np.reshape(mal_img,(mal_img.shape[0],-1))).T) + b_mal)
    log_pred=np.argmax(log_pred,axis=0)
    log_pred=[k for k,v in keys.items() if v==log_pred]
    
    print("prediction by CNN model is {}".format(cnn_pred))
    print("prediction by logistic regression model is {}".format(log_pred))
    print("prediction by random forest is {}".format(rf_pred))
    
elif ch=="2":
    file=open('trainingmetric.txt','r')
    data=file.read()
    print(data)
    
    plt1=cv.imread('log_reg.jpg')
    plt2=cv.imread('con_mat_cnn.jpg')
    plt3=cv.imread('con_mat_randomforest.jpg')
    
    plt.imshow(plt1)
    plt.imshow(plt2)
    plt.imshow(plt3)
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

